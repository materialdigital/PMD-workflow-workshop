{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating a generic, non-python tool in pyiron (Level B, recommended approach)\n",
    "To integrate a new tool into pyiron, one needs to create a pyiron job class, which is inherited from pyiron generic job class: `GenericJob`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import GenericJob, GenericParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the job class\n",
    "Here, as a simple and generic process, we would like to use the bash command `cat` to print some values in an output file.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyBashJob(GenericJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super().__init__(project, job_name) \n",
    "        self.input = GenericParameters(table_name=\"input\")\n",
    "        self.input['input_energy'] = 100\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self): \n",
    "        self.input.write_file( \n",
    "            file_name=\"input\",\n",
    "            cwd=self.working_directory\n",
    "        )\n",
    "\n",
    "    def collect_output(self):\n",
    "        file = join(self.working_directory, \"output\") \n",
    "        with open(file) as f:\n",
    "            line = f.readlines()[0]\n",
    "        energy = float(line.split()[1]) \n",
    "        with self.project_hdf5.open(\"output/generic\") as h5out: \n",
    "            h5out[\"energy_tot\"] = energy\n",
    "\n",
    "    def to_hdf(self, hdf=None, group_name=None): \n",
    "        super().to_hdf(\n",
    "            hdf=hdf,\n",
    "            group_name=group_name\n",
    "        )\n",
    "        with self.project_hdf5.open(\"input\") as h5in:\n",
    "            self.input.to_hdf(h5in)\n",
    "\n",
    "    def from_hdf(self, hdf=None, group_name=None): \n",
    "        super().from_hdf(\n",
    "            hdf=hdf,\n",
    "            group_name=group_name\n",
    "        )\n",
    "        with self.project_hdf5.open(\"input\") as h5in:\n",
    "            self.input.from_hdf(h5in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  \n",
    "using the above job class, create a project and run a job of type `ToyBashJob` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
